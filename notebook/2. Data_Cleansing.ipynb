{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749657d4",
   "metadata": {},
   "source": [
    "# 1. Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40b1ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_dir = '../dataset/phase 2/'\n",
    "file_path_1 = os.path.join(base_dir, 'df_translated_google_play.csv')\n",
    "file_path_2 = os.path.join(base_dir, 'df_translated_app_store.csv')\n",
    "\n",
    "df_1 = pd.read_csv(file_path_1)\n",
    "df_2 = pd.read_csv(file_path_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773a3dd",
   "metadata": {},
   "source": [
    "# 2. Combine Dataset From Play Store and App Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c66d2dc",
   "metadata": {},
   "source": [
    "## 2.1. App Name Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adbc7520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['app'] = df_1['app'].replace('Hazards - Red Cross', 'Hazards Red Cross')\n",
    "\n",
    "df_2['app'] = df_2['app'].replace('GeoNet Quake', 'GeoNet')\n",
    "df_2['app'] = df_2['app'].replace('Hazards – Red Cross', 'Hazards Red Cross')\n",
    "df_2['app'] = df_2['app'].replace('Disaster Alert (PDC Global)', 'Disaster Alert')\n",
    "df_2['app'] = df_2['app'].replace('Earthquake+ Alerts Map & Info', 'Earthquake + Alerts Map & Info')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a54c9",
   "metadata": {},
   "source": [
    "## 2.2. Concat Play store and App Store dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53e52f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1[['app', 'content', 'score']], df_2[['app', 'content', 'score']]], ignore_index = True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cecfe9",
   "metadata": {},
   "source": [
    "# 3. Filter Natural Disaster App Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be5af100",
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_disaster_app_name = ['Earthquake Alert!', 'My Earthquake Alerts - Map', 'Earthquakes Tracker', 'Yurekuru Call', \n",
    "                        'Wind Map Hurricane Tracker 3D', 'global storms', 'FEMA',\n",
    "                        'Volcanoes & Earthquakes', 'Hazards Near Me NSW', 'Disaster Alert',\n",
    "                        'Tropical Hurricane Tracker', 'GeoNet', 'My Hurricane Tracker & Alerts',\n",
    "                        'Emergency: Severe Weather App', 'Hurricane Tracker', 'Hazards Red Cross',\n",
    "                        'NINA - Die Warn-App des BBK', 'SeaStorm Hurricane Tracker', 'National evacuation center guide',\n",
    "                        'My Hurricane Tracker Pro', 'Alert SA', 'Floods Near Me NSW', 'Safety tips',\n",
    "                        'Earthquake', 'Earthquake + Alerts Map & Info', 'Natural Disaster Monitor',\n",
    "                        'Earthquakes Today', 'FloodAlert Waterlevel Alerts', 'NERV Disaster Prevention', \n",
    "                        'SES Assistance QLD', 'Hurricane & Typhoon Track',\n",
    "                        'QuakeFeed Earthquake Tracker', 'LastQuake', 'VIC Fires', \n",
    "                        'VicEmergency', 'CodeRED Mobile Alert', 'myAlerts', 'SD Emergency',\n",
    "                        'Emergency', 'Alertswiss', 'Alert2Me - Emergency Alerts', 'BD 999',\n",
    "                        'KwiKam (Quicking Services)', 'Emergency Ready App', 'Anhaar'\n",
    "                       ]\n",
    "df = df[df.app.isin(natural_disaster_app_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e82b9f8",
   "metadata": {},
   "source": [
    "# 4. Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e662491",
   "metadata": {},
   "source": [
    "## 4.1. Remove Data Duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7978b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['content', 'app'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7a2db",
   "metadata": {},
   "source": [
    "## 4.2. Remove Empty Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c04256cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f5714",
   "metadata": {},
   "source": [
    "## 4.3. Remove Short Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46420550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(word_count=lambda x: x['content'].apply(lambda text: len(str(text).split()))).query('word_count > 4')\n",
    "df = df[['app', 'content', 'score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a3f67c",
   "metadata": {},
   "source": [
    "## 4.4. Remove Zero Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94da9b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.score != 0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a064c74",
   "metadata": {},
   "source": [
    "## 4.5. Remove Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c089dccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "import re\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               u\"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # Various Asian characters\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # various technical, arrows, geometric and drawing\n",
    "                               u\"\\U0001F926-\\U0001F937\"  # Supplemental Symbols and Pictographs\n",
    "                               u\"\\U00010000-\\U0010FFFF\"  # Other additional symbols\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "df['content'] = df['content'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798fdc1",
   "metadata": {},
   "source": [
    "# 5. Shorten User Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8538968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhamadsyukron/opt/anaconda3/envs/emergency-app-1/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 reviews in 186.42636132240295 seconds\n",
      "Processed 1000 reviews in 160.45618295669556 seconds\n",
      "Processed 1500 reviews in 170.79099416732788 seconds\n",
      "Processed 2000 reviews in 172.19620084762573 seconds\n",
      "Processed 2500 reviews in 159.82256984710693 seconds\n",
      "Processed 3000 reviews in 154.8026683330536 seconds\n",
      "Processed 3500 reviews in 159.95489287376404 seconds\n",
      "Processed 4000 reviews in 156.24324226379395 seconds\n",
      "Processed 4500 reviews in 171.52524876594543 seconds\n",
      "Processed 5000 reviews in 172.09528970718384 seconds\n",
      "Processed 5500 reviews in 169.3285629749298 seconds\n",
      "Processed 6000 reviews in 154.22064661979675 seconds\n",
      "Processed 6500 reviews in 199.30241012573242 seconds\n",
      "Processed 7000 reviews in 202.18596029281616 seconds\n",
      "Processed 7500 reviews in 180.31750965118408 seconds\n",
      "Processed 8000 reviews in 159.18331146240234 seconds\n",
      "Processed 8500 reviews in 159.2018096446991 seconds\n",
      "Processed 9000 reviews in 157.96987962722778 seconds\n",
      "Processed 9500 reviews in 165.9948661327362 seconds\n",
      "Processed 10000 reviews in 171.5184669494629 seconds\n",
      "Processed 10500 reviews in 167.8985686302185 seconds\n",
      "Processed 11000 reviews in 165.58395862579346 seconds\n",
      "Processed 11500 reviews in 193.9168632030487 seconds\n",
      "Processed 12000 reviews in 197.60406064987183 seconds\n",
      "Processed 12500 reviews in 175.96352791786194 seconds\n",
      "Processed 13000 reviews in 179.42393827438354 seconds\n",
      "Processed 13500 reviews in 170.77535557746887 seconds\n",
      "Processed 14000 reviews in 165.48673820495605 seconds\n",
      "Processed 14500 reviews in 169.1692841053009 seconds\n",
      "Processed 15000 reviews in 173.1460781097412 seconds\n",
      "Processed 15500 reviews in 196.67502737045288 seconds\n",
      "Processed 16000 reviews in 197.87746953964233 seconds\n",
      "Processed 16500 reviews in 218.01117086410522 seconds\n",
      "Processed 17000 reviews in 203.31480169296265 seconds\n",
      "Processed 17500 reviews in 231.30008029937744 seconds\n",
      "Processed 18000 reviews in 235.7626850605011 seconds\n",
      "Processed 18500 reviews in 217.3102514743805 seconds\n",
      "Processed 19000 reviews in 214.2841775417328 seconds\n",
      "Processed 19500 reviews in 221.8610897064209 seconds\n",
      "Processed 20000 reviews in 297.92032623291016 seconds\n",
      "Processed 20500 reviews in 223.1890983581543 seconds\n",
      "Processed 21000 reviews in 226.26953125 seconds\n",
      "Processed 21500 reviews in 204.27802419662476 seconds\n",
      "Processed 22000 reviews in 187.1706142425537 seconds\n",
      "Processed 22500 reviews in 280.21262860298157 seconds\n",
      "Processed 23000 reviews in 219.40811157226562 seconds\n",
      "Processed 23500 reviews in 185.54940938949585 seconds\n",
      "Processed 24000 reviews in 332.4929497241974 seconds\n",
      "Processed 24500 reviews in 211.27086186408997 seconds\n",
      "Processed 25000 reviews in 172.4677984714508 seconds\n",
      "Processed 25500 reviews in 171.65533828735352 seconds\n",
      "Processed 26000 reviews in 213.00336408615112 seconds\n",
      "Processed 26500 reviews in 295.7635552883148 seconds\n",
      "Processed 27000 reviews in 297.70833921432495 seconds\n",
      "Processed 27500 reviews in 259.7859582901001 seconds\n",
      "Processed 28000 reviews in 183.54772925376892 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "from transformers import pipeline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize the model and tokenizer once\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "qa_pipeline = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "\n",
    "def qna(review, qa_pipeline):\n",
    "    question = \"What is the user's complaint or suggestion about the natural disaster emergency app?\"\n",
    "    \n",
    "    # Get the answer\n",
    "    answer = qa_pipeline({\n",
    "        'context': review,\n",
    "        'question': question\n",
    "    })\n",
    "    return answer['answer']\n",
    "\n",
    "result = []\n",
    "index = 0\n",
    "total_time = 0  # Initialize total time\n",
    "\n",
    "for review in df['content']:\n",
    "    start_time = time.time()  # Start time measurement\n",
    "\n",
    "    # Call the qna function with the pipeline\n",
    "    answer = qna(review, qa_pipeline)\n",
    "    result.append(answer)\n",
    "\n",
    "    end_time = time.time()  # End time measurement\n",
    "    total_time += end_time - start_time  # Accumulate the total time\n",
    "\n",
    "    index += 1\n",
    "    if index % 500 == 0:\n",
    "        print(f\"Processed {index} reviews in {total_time} seconds\")\n",
    "        total_time = 0  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27545eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content_short'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b327d80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>content_short</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disaster Alert</td>\n",
       "      <td>Working as a Public Health Nurse I get to resp...</td>\n",
       "      <td>5</td>\n",
       "      <td>I may have lost and/or procured gadgets to aid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Disaster Alert</td>\n",
       "      <td>Nice to have before traveling to unknown terri...</td>\n",
       "      <td>5</td>\n",
       "      <td>Nice to have before traveling to unknown terri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disaster Alert</td>\n",
       "      <td>I like! I'm trying to find anything about tsun...</td>\n",
       "      <td>5</td>\n",
       "      <td>tsunami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disaster Alert</td>\n",
       "      <td>good to have but what options are expected in ...</td>\n",
       "      <td>5</td>\n",
       "      <td>good to have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disaster Alert</td>\n",
       "      <td>Shows hazards all right but refuses to send no...</td>\n",
       "      <td>2</td>\n",
       "      <td>Useless to me without notifications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28156</th>\n",
       "      <td>Earthquake</td>\n",
       "      <td>It works quite well even anticipates some othe...</td>\n",
       "      <td>5</td>\n",
       "      <td>works quite well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28157</th>\n",
       "      <td>Earthquake</td>\n",
       "      <td>This application is very good.</td>\n",
       "      <td>5</td>\n",
       "      <td>This application is very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28158</th>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Data from earthquakes in Chile in the last 24 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>the application is not updating the telluric a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28159</th>\n",
       "      <td>Earthquake</td>\n",
       "      <td>This is as good as earthquake apps can go. Thi...</td>\n",
       "      <td>5</td>\n",
       "      <td>detailed info on many earthquakes that even ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28160</th>\n",
       "      <td>Earthquake</td>\n",
       "      <td>Delivers everything described in the write-up ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Delivers everything described in the write-up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28161 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  app                                            content  \\\n",
       "0      Disaster Alert  Working as a Public Health Nurse I get to resp...   \n",
       "1      Disaster Alert  Nice to have before traveling to unknown terri...   \n",
       "2      Disaster Alert  I like! I'm trying to find anything about tsun...   \n",
       "3      Disaster Alert  good to have but what options are expected in ...   \n",
       "4      Disaster Alert  Shows hazards all right but refuses to send no...   \n",
       "...               ...                                                ...   \n",
       "28156      Earthquake  It works quite well even anticipates some othe...   \n",
       "28157      Earthquake                     This application is very good.   \n",
       "28158      Earthquake  Data from earthquakes in Chile in the last 24 ...   \n",
       "28159      Earthquake  This is as good as earthquake apps can go. Thi...   \n",
       "28160      Earthquake  Delivers everything described in the write-up ...   \n",
       "\n",
       "       score                                      content_short  \n",
       "0          5  I may have lost and/or procured gadgets to aid...  \n",
       "1          5  Nice to have before traveling to unknown terri...  \n",
       "2          5                                            tsunami  \n",
       "3          5                                       good to have  \n",
       "4          2                Useless to me without notifications  \n",
       "...      ...                                                ...  \n",
       "28156      5                                   works quite well  \n",
       "28157      5                      This application is very good  \n",
       "28158      2  the application is not updating the telluric a...  \n",
       "28159      5  detailed info on many earthquakes that even ot...  \n",
       "28160      5      Delivers everything described in the write-up  \n",
       "\n",
       "[28161 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db14a2",
   "metadata": {},
   "source": [
    "# 6. Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122034b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../dataset/phase_3'\n",
    "output_path = os.path.join(save_dir, 'topic_modelling_dataset.csv')\n",
    "\n",
    "df.to_csv(output_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589682d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (emergency-app-1)",
   "language": "python",
   "name": "emergency-app-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
